# ゐ拆 Documentaci贸n Web Crawler - Redes Sociales 佛拆

A continuaci贸n se muestra una breve documentaci贸n del web crawler de redes sociales. Este, tiene la funci贸n y objetivo de buscar y analizar perfiles de distintas redes y usuarios para recopilar informaci贸n. Al ejecutar este c贸digo, se genera una carpeta llamada "Redes Sociales" y dentro de ella se guardan las fotos de perfil de los usuarios a buscar y adem谩s se genera un txt con la informaci贸n principal de los mismo, tal como sus seguidores, likes, posts, etc.
#

```python
import os
import requests
from bs4 import BeautifulSoup
from urllib.request import urlretrieve
```
- Se importan los m贸dulos necesarios para la ejecuci贸n del script, os es un m贸dulo de Python que se utiliza para interactuar con el sistema operativo, en este caso se utilizar谩 para crear la carpeta "Redes sociales" si no existe. 
- Requests es un m贸dulo que se utiliza para realizar solicitudes HTTP a las p谩ginas web. 
- BeautifulSoup es un m贸dulo que se utiliza para analizar el contenido HTML de las p谩ginas web y urlretrieve es un m贸dulo que se utiliza para descargar las im谩genes de perfil y guardarlas en la carpeta "Redes sociales".

```python
urls = [
    'https://www.facebook.com/zuck',
    'https://www.facebook.com/DwayneJohnson',
    'https://www.instagram.com/billieeilish/',
    'https://www.instagram.com/jeffbezos/',
]

```
En esta secci贸n se establece una lista de URLs de perfiles de redes sociales que se desea analizar. En este caso, se han elegido cuatro perfiles de Facebook e Instagram.

```python
if not os.path.exists('Redes sociales'):
    os.mkdir('Redes sociales')

```
En esta secci贸n se comprueba si la carpeta "Redes sociales" existe en el sistema y, en caso contrario, se crea.

```python
for url in urls:
    try:
        response = requests.get(url)
        html_content = response.content
    except requests.exceptions.RequestException as e:
        print(e)
        continue

    soup = BeautifulSoup(html_content, 'html.parser')
    name_element = soup.find('title')
    if name_element is not None:
        name = name_element.text.strip()
    else:
        name = 'Nombre no encontrado'
    profile_image_element = soup.find('meta', property='og:image')
    if profile_image_element is not None:
        profile_image_url = profile_image_element['content']
    else:
        profile_image_url = None
    description_element = soup.find('meta', property='og:description')
    if description_element is not None:
        description = description_element['content']
    else:
        description = 'Descripci贸n no encontrada'

```
- En esta secci贸n se itera sobre cada URL en la lista urls y se realiza el an谩lisis correspondiente
- Primero se realiza una solicitud HTTP a la p谩gina web y se obtiene el contenido HTML. 
- Se utiliza BeautifulSoup para analizar el contenido HTML y extraer informaci贸n relevante, como el nombre del perfil, la URL de la imagen de perfil y la descripci贸n del perfil.


```python
with open(f"Redes sociales/{name}.txt", "w", encoding="utf-8") as file:
        file.write(description)

```
En este c贸digo, la l铆nea with open(...) crea el archivo y lo mantiene abierto mientras se ejecuta el bloque de c贸digo indentado que sigue. Una vez que se sale del bloque with, el archivo se cierra autom谩ticamente.

# Outputs
 ## Impresi贸n en consola del web crawler de Redes Sociales.
 
![Imagen impresi贸n en consola del web crawler de Redes Sociales.](/Img/outputRedes.png)
 
#
 ## Generaci贸n de carpeta en la carpeta raiz.
 
 ![Imagen generaci贸n de carpeta en la carpeta raiz..](/Img/carpRedes.png)
 
#
 ## Contenido de la carpeta Redes Sociales.
 
 ![Imagen contenido de la carpeta Redes Sociales.](/Img/archivosRedes.png)
 
---

Copyright 漏 2023 Yessenia Paola Carbajal Armenta. 

Este proyecto se cre贸 como parte del curso "Programaci贸n para Internet" en el a帽o 2023.

---
